\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\gdef\hy@title{Bayesian Restricted Likelihood Methods: Conditioning on Insufficient Statistics in Bayesian Regression}
\thanksnewlabel{T1thanks}{{\TextOrMath  {\textasteriskcentered }{*}}{1}}
\thanksnewlabel{e1@email}{{lewis.865@osu.edu}{1}}
\thanksnewlabel{e2@email}{{snm@stat.osu.edu}{1}}
\thanksnewlabel{e3@email}{{yklee@stat.osu.edu}{1}}
\thanksnewlabel{addr1thanks}{{\TextOrMath  {\textdagger }{\dagger }}{1}}
\citation{garthwaite2005,ohagan2006}
\citation{berger2006}
\citation{kass1995}
\citation{lee2014}
\gdef\hy@author{John R. Lewis, Steven N. MacEachern and Yoonkyung Lee}
\gdef\hy@subject{Bayesian Analysis0000 0001}
\gdef\hy@keywords{Approximate Bayesian computation, Markov chain Monte Carlo, M-estimation, Robust regression}
\gdef\author@num{3}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\@writefile{brf}{\backcite{garthwaite2005}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{ohagan2006}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{berger2006}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{kass1995}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{lee2014}{{3}{1}{section.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Restricted Likelihood}{3}{section.2}}
\newlabel{restrictedlikelihood}{{2}{3}{Restricted Likelihood}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Examples}{3}{subsection.2.1}}
\citation{ratcliff1993}
\citation{lewis2014}
\newlabel{OutlyingCases}{{1}{4}{Examples}{equation.2.1}{}}
\@writefile{brf}{\backcite{ratcliff1993}{{4}{2.1}{equation.2.1}}}
\newlabel{Censoring}{{2}{4}{Examples}{equation.2.2}{}}
\@writefile{brf}{\backcite{lewis2014}{{4}{2.1}{equation.2.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Generalization}{4}{subsection.2.2}}
\newlabel{FullLikelihood}{{3}{4}{Generalization}{equation.2.3}{}}
\citation{savage1969}
\citation{pettitt1983,pettitt1982}
\citation{hoff2013}
\citation{lewis2012}
\citation{doksum1990}
\citation{clarke1995}
\citation{yuan2004}
\citation{hwang2005}
\citation{pratt1965}
\citation{tavare1997,pritchard1999,marjoram2003,fearnhead2012}
\citation{joyce2008}
\newlabel{RestrictedPosterior}{{4}{5}{Generalization}{equation.2.4}{}}
\newlabel{RestrictedpredDist}{{5}{5}{Generalization}{equation.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Literature review}{5}{subsection.2.3}}
\@writefile{brf}{\backcite{savage1969}{{5}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{pettitt1983}{{5}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{pettitt1982}{{5}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{hoff2013}{{5}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{lewis2012}{{5}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{doksum1990}{{5}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{clarke1995}{{5}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{yuan2004}{{5}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{hwang2005}{{5}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{pratt1965}{{5}{2.3}{subsection.2.3}}}
\citation{huber2009}
\@writefile{brf}{\backcite{tavare1997}{{6}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{pritchard1999}{{6}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{marjoram2003}{{6}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{fearnhead2012}{{6}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{joyce2008}{{6}{2.3}{subsection.2.3}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Illustrative Examples}{6}{section.3}}
\newlabel{illustrations}{{3}{6}{Illustrative Examples}{section.3}{}}
\citation{kass1995reference}
\@writefile{brf}{\backcite{huber2009}{{7}{3}{equation.3.6}}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces asdfdfa}}{8}{figure.1}}
\newlabel{fig:newcomb_post}{{1}{8}{asdfdfa}{figure.1}{}}
\@writefile{brf}{\backcite{kass1995reference}{{8}{3}{equation.3.7}}}
\citation{huber1964}
\citation{lewis2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Predictive distribution of log(calls) under the Normal theory model fit to the non-outliers, the restricted likelihood model with Tukey's M-estimator for the slope and intercept with Huber's `proposal 2' for scale, and a heavy-tailed t-distribution model. The first three data points were used to specify the prior with the remaining points used in the posterior fits. See details in the Appendix.}}{9}{figure.2}}
\newlabel{fig:calls_predictive}{{2}{9}{Predictive distribution of log(calls) under the Normal theory model fit to the non-outliers, the restricted likelihood model with Tukey's M-estimator for the slope and intercept with Huber's `proposal 2' for scale, and a heavy-tailed t-distribution model. The first three data points were used to specify the prior with the remaining points used in the posterior fits. See details in the Appendix}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Restricted Likelihood for the Linear Model}{9}{section.4}}
\newlabel{BayesLinMod}{{4}{9}{Restricted Likelihood for the Linear Model}{section.4}{}}
\@writefile{brf}{\backcite{huber1964}{{9}{4}{section.4}}}
\@writefile{brf}{\backcite{lewis2014}{{10}{4}{section.4}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}The Bayesian linear model}{10}{subsection.4.1}}
\newlabel{LinearModel}{{8}{10}{The Bayesian linear model}{equation.4.8}{}}
\newlabel{fullRank}{{C1}{10}{The Bayesian linear model}{equation.4.8}{}}
\newlabel{supReal}{{C2}{10}{The Bayesian linear model}{equation.4.8}{}}
\newlabel{asb}{{C3}{10}{The Bayesian linear model}{equation.4.8}{}}
\newlabel{as}{{C4}{10}{The Bayesian linear model}{equation.4.8}{}}
\citation{huber2009,maronna2006}
\citation{lewis2014}
\citation{gelfand1990}
\citation{liu1994,liang2008}
\citation{hastings1970}
\newlabel{regEq}{{C5}{11}{The Bayesian linear model}{equation.4.8}{}}
\newlabel{scaleEqReg}{{C6}{11}{The Bayesian linear model}{equation.4.8}{}}
\newlabel{regIn}{{C7}{11}{The Bayesian linear model}{equation.4.8}{}}
\newlabel{scaleEq2Reg}{{C8}{11}{The Bayesian linear model}{equation.4.8}{}}
\@writefile{brf}{\backcite{huber2009}{{11}{4.1}{equation.4.8}}}
\@writefile{brf}{\backcite{maronna2006}{{11}{4.1}{equation.4.8}}}
\@writefile{brf}{\backcite{lewis2014}{{11}{4.1}{equation.4.8}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Computational strategy}{11}{subsection.4.2}}
\newlabel{highDim}{{4.2}{11}{Computational strategy}{subsection.4.2}{}}
\@writefile{brf}{\backcite{gelfand1990}{{11}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{liu1994}{{11}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{liang2008}{{11}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{hastings1970}{{11}{4.2}{subsection.4.2}}}
\newlabel{MHRatio}{{9}{12}{Computational strategy}{equation.4.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{Construction of the proposal}{12}{section*.1}}
\newlabel{Transformation}{{4.1}{12}{}{theorem.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Evaluation of the proposal density}{14}{section*.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A depiction of $\mathcal  {A}$, $\Pi (\mathcal  {A})$, and the unit circle for the illustrative example where $b_{1}(\mathbf  {1},\unhbox \voidb@x \hbox {\relax \mathversion  {bold}$y$})=\qopname  \relax m{min}(\unhbox \voidb@x \hbox {\relax \mathversion  {bold}$y$})=0$ and $s(\mathbf  {1},\unhbox \voidb@x \hbox {\relax \mathversion  {bold}$y$})=\DOTSB \sum@ \slimits@ (y_i -b_{1}(\mathbf  {1},\unhbox \voidb@x \hbox {\relax \mathversion  {bold}$y$}))^2 =1$. $\mathcal  {A}$ is the combination of three quarter circles, one on each plane defined by $y_i=0$. The projection of this manifold onto the deviation space is depicted by the bowed triangular shape in the plane defined by $\DOTSB \sum@ \slimits@ y_i=0$. The circle in this plane represents the sample space for the intermediate sample $\unhbox \voidb@x \hbox {\relax \mathversion  {bold}$z$}^*$. Also depicted is the vector $\mathbf  {1}$, the design matrix for the location and scale setting.}}{15}{figure.3}}
\newlabel{fig:sampSpace}{{3}{15}{A depiction of $\mathcal {A}$, $\Pi (\mathcal {A})$, and the unit circle for the illustrative example where $b_{1}(\mathbf {1},\by )=\min (\by )=0$ and $s(\mathbf {1},\by )=\sum (y_i -b_{1}(\mathbf {1},\by ))^2 =1$. $\mathcal {A}$ is the combination of three quarter circles, one on each plane defined by $y_i=0$. The projection of this manifold onto the deviation space is depicted by the bowed triangular shape in the plane defined by $\sum y_i=0$. The circle in this plane represents the sample space for the intermediate sample $\bz ^*$. Also depicted is the vector $\mathbf {1}$, the design matrix for the location and scale setting}{figure.3}{}}
\newlabel{gradSTheoremReg}{{4.2}{15}{}{theorem.4.2}{}}
\newlabel{cosine}{{12}{15}{Evaluation of the proposal density}{equation.4.12}{}}
\newlabel{fig:stretchDeform}{{4.2}{16}{Evaluation of the proposal density}{equation.4.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces sdasfda}}{16}{figure.4}}
\newlabel{lem:basis}{{4.3}{16}{}{theorem.4.3}{}}
\citation{miao1992}
\citation{miao1992}
\newlabel{lem:fullrank}{{4.4}{17}{}{theorem.4.4}{}}
\newlabel{eq:volume}{{13}{17}{Evaluation of the proposal density}{equation.4.13}{}}
\@writefile{brf}{\backcite{miao1992}{{17}{4.2}{equation.4.13}}}
\newlabel{Jacobian}{{4.5}{17}{}{theorem.4.5}{}}
\newlabel{dens:ystst}{{14}{17}{}{equation.4.14}{}}
\@writefile{brf}{\backcite{miao1992}{{18}{4.2}{equation.4.14}}}
\newlabel{theorem:sings}{{4.7}{18}{}{theorem.4.7}{}}
\newlabel{Mest}{{15}{18}{Evaluation of the proposal density}{equation.4.15}{}}
\citation{huber2009}
\@writefile{toc}{\contentsline {section}{\numberline {5}Simulated Data}{19}{section.5}}
\newlabel{simData}{{5}{19}{Simulated Data}{section.5}{}}
\newlabel{gensim2}{{16}{19}{Simulated Data}{equation.5.16}{}}
\newlabel{fullsim2}{{17}{19}{Simulated Data}{equation.5.17}{}}
\@writefile{brf}{\backcite{huber2009}{{19}{5}{equation.5.17}}}
\citation{huber2009}
\newlabel{kl}{{18}{20}{Simulated Data}{equation.5.18}{}}
\newlabel{kl_sim}{{5}{21}{Simulated Data}{equation.5.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Average KL - divergence plus/minus one standard error for each value of $a_{s}$ and $c$. The panels correspond to $c = 0.5$ (left), $c=1$ (middle), and $c=2$ (right) with the values of $a_{s}$ on the horizontal axis.}}{21}{figure.5}}
\@writefile{brf}{\backcite{huber2009}{{21}{5}{equation.5.18}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Average KL - divergence plus/minus one standard error grouped by the factors $m$ (left), $n$ (middle), and $p$ (right)}}{22}{figure.6}}
\newlabel{kl_mnp}{{6}{22}{Average KL - divergence plus/minus one standard error grouped by the factors $m$ (left), $n$ (middle), and $p$ (right)}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Boxplots $(\theta _{i} - \mathaccentV {hat}05E\theta _{i})$ across all simulations separated by the values for $m$ (left), $n$ (middle), $p$ (right) where $\mathaccentV {hat}05E\theta _{i}$ are the classical robust estimators (Huber's and Tukey's).}}{23}{figure.7}}
\newlabel{boxTheta}{{7}{23}{Boxplots $(\theta _{i} - \hat \theta _{i})$ across all simulations separated by the values for $m$ (left), $n$ (middle), $p$ (right) where $\hat \theta _{i}$ are the classical robust estimators (Huber's and Tukey's)}{figure.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Real Data}{23}{section.6}}
\newlabel{Real Data}{{6}{23}{Real Data}{section.6}{}}
\citation{zellner1986,liang2008}
\citation{kass1995reference}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Boxplots of the classical robust estimators (Huber's and Tukey's) for $\sigma _{i}$ across all simulations separated by the values for $m$ (left), $n$ (middle), $p$ (right). The horizontal line at $\sigma = 2$ highlights the true standard deviation of the `good' data.}}{24}{figure.8}}
\newlabel{boxSigma}{{8}{24}{Boxplots of the classical robust estimators (Huber's and Tukey's) for $\sigma _{i}$ across all simulations separated by the values for $m$ (left), $n$ (middle), $p$ (right). The horizontal line at $\sigma = 2$ highlights the true standard deviation of the `good' data}{figure.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}State Level Regression model}{24}{subsection.6.1}}
\newlabel{regModelNW}{{6.1}{24}{State Level Regression model}{subsection.6.1}{}}
\newlabel{eq:regModel}{{19}{24}{State Level Regression model}{equation.6.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The square root of count in 2012 versus that in 2010 (after centering and scaling). The colors represent the varying contractual agreements as they stood in 2010. Agencies that closed during the 2010-2012 period are represented by the zero counts for 2012. Scalings on the axes are purposely left off for proprietary reasons.}}{25}{figure.9}}
\newlabel{fig:ctVct}{{9}{25}{The square root of count in 2012 versus that in 2010 (after centering and scaling). The colors represent the varying contractual agreements as they stood in 2010. Agencies that closed during the 2010-2012 period are represented by the zero counts for 2012. Scalings on the axes are purposely left off for proprietary reasons}{figure.9}{}}
\@writefile{brf}{\backcite{zellner1986}{{25}{6.1}{equation.6.19}}}
\@writefile{brf}{\backcite{liang2008}{{25}{6.1}{equation.6.19}}}
\@writefile{brf}{\backcite{kass1995reference}{{25}{6.1}{equation.6.19}}}
\citation{ronchetti1997}
\citation{jung2014}
\@writefile{toc}{\contentsline {subsubsection}{Method of model comparison}{26}{section*.3}}
\@writefile{brf}{\backcite{ronchetti1997}{{26}{6.1}{section*.3}}}
\@writefile{brf}{\backcite{jung2014}{{26}{6.1}{section*.3}}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison of predictive performance}{27}{section*.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Average TLM plus/minus one standard deviation over $K = 50$ splits into training and holdout samples. The panels are for the different states 2, 15, 27, and 36, with $n = 222, 40, 117,$ and $46$, respectively. The horizontal axis is the percent of $n$ used in each training set. The color corresponds to the fitting model. }}{28}{figure.10}}
\newlabel{fig:tlm}{{10}{28}{Average TLM plus/minus one standard deviation over $K = 50$ splits into training and holdout samples. The panels are for the different states 2, 15, 27, and 36, with $n = 222, 40, 117,$ and $46$, respectively. The horizontal axis is the percent of $n$ used in each training set. The color corresponds to the fitting model}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Average TLM plus/minus one standard deviation over $K = 50$ splits into training and holdout samples for several values of the trimming fraction $\alpha $. The training sample size used is $0.5n$.}}{29}{figure.11}}
\newlabel{fig:tlmbyAlpha}{{11}{29}{Average TLM plus/minus one standard deviation over $K = 50$ splits into training and holdout samples for several values of the trimming fraction $\alpha $. The training sample size used is $0.5n$}{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Hierarchical regression model}{29}{subsection.6.2}}
\newlabel{hierRegNW}{{6.2}{29}{Hierarchical regression model}{subsection.6.2}{}}
\newlabel{eq:hierModel}{{20}{29}{Hierarchical regression model}{equation.6.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{31}{section.7}}
\newlabel{Conclusions}{{7}{31}{Discussion}{section.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Appendix}{32}{section.8}}
\newlabel{sec:appendix}{{8}{32}{Appendix}{section.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Proofs}{32}{subsection.8.1}}
\newlabel{perpGradReg}{{8.1}{33}{Proofs}{equation.8.21}{}}
\newlabel{eq:lem3.2}{{26}{33}{Proofs}{equation.8.26}{}}
\newlabel{BigMatrix}{{27}{33}{Proofs}{equation.8.27}{}}
\citation{miao1992}
\@writefile{brf}{\backcite{miao1992}{{34}{8.1}{equation.8.27}}}
\newlabel{MBI:lemma}{{8.1}{34}{}{theorem.8.1}{}}
\newlabel{MBI:thm}{{8.2}{34}{}{theorem.8.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Setting the hierarchical prior values}{35}{subsection.8.2}}
\bibstyle{bib/ba}
\bibdata{bib/refPaper1}
\bibcite{berger2006}{{1}{2006}{{Berger}}{{}}}
\bibcite{clarke1995}{{2}{1995}{{Clarke and Ghosh}}{{}}}
\bibcite{doksum1990}{{3}{1990}{{Doksum and Lo}}{{}}}
\bibcite{fearnhead2012}{{4}{2012}{{Fearnhead and Prangle}}{{}}}
\bibcite{garthwaite2005}{{5}{2005}{{Garthwaite et~al.}}{{}}}
\bibcite{gelfand1990}{{6}{1990}{{Gelfand and Smith}}{{}}}
\bibcite{hastings1970}{{7}{1970}{{Hastings}}{{}}}
\bibcite{hoff2013}{{8}{2013}{{Hoff et~al.}}{{}}}
\bibcite{huber2009}{{9}{2009}{{Huber and Ronchetti}}{{}}}
\bibcite{huber1964}{{10}{1964}{{Huber}}{{}}}
\@writefile{toc}{\contentsline {section}{References}{36}{section*.6}}
\bibcite{hwang2005}{{11}{2005}{{Hwang et~al.}}{{}}}
\bibcite{joyce2008}{{12}{2008}{{Joyce and Marjoram}}{{}}}
\bibcite{jung2014}{{13}{2014}{{Jung et~al.}}{{}}}
\bibcite{kass1995}{{14}{1995}{{Kass and Raftery}}{{}}}
\bibcite{kass1995reference}{{15}{1995}{{Kass and Wasserman}}{{}}}
\bibcite{lee2014}{{16}{2014}{{Lee and MacEachern}}{{}}}
\bibcite{lewis2014}{{17}{2014}{{Lewis}}{{}}}
\bibcite{lewis2012}{{18}{2012}{{Lewis et~al.}}{{}}}
\bibcite{liang2008}{{19}{2008}{{Liang et~al.}}{{}}}
\bibcite{liu1994}{{20}{1994}{{Liu}}{{}}}
\bibcite{marjoram2003}{{21}{2003}{{Marjoram et~al.}}{{}}}
\bibcite{maronna2006}{{22}{2006}{{Maronna et~al.}}{{}}}
\bibcite{miao1992}{{23}{1992}{{Miao and Ben-Israel}}{{}}}
\bibcite{ohagan2006}{{24}{2006}{{O'Hagan et~al.}}{{}}}
\bibcite{pettitt1982}{{25}{1982}{{Pettitt}}{{}}}
\bibcite{pettitt1983}{{26}{1983}{{Pettitt}}{{}}}
\bibcite{pratt1965}{{27}{1965}{{Pratt}}{{}}}
\bibcite{pritchard1999}{{28}{1999}{{Pritchard et~al.}}{{}}}
\bibcite{ratcliff1993}{{29}{1993}{{Ratcliff}}{{}}}
\bibcite{ronchetti1997}{{30}{1997}{{Ronchetti et~al.}}{{}}}
\bibcite{savage1969}{{31}{1969}{{Savage}}{{}}}
\bibcite{tavare1997}{{32}{1997}{{Tavar{\'e} et~al.}}{{}}}
\bibcite{yuan2004}{{33}{2004}{{Yuan and Clarke}}{{}}}
\bibcite{zellner1986}{{34}{1986}{{Zellner}}{{}}}
