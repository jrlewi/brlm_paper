\relax 
\citation{garthwaite2005,ohagan2006}
\citation{berger2006}
\citation{kass1995}
\citation{yuan1999minimally}
\citation{zhu2011}
\citation{clyde2004}
\citation{bernardo2000,clyde2013,clarke2013Complete}
\citation{lee2014}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Restricted Likelihood}{4}}
\newlabel{restrictedlikelihood}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Examples}{4}}
\citation{ratcliff1993}
\citation{lewis2014}
\newlabel{OutlyingCases}{{1}{5}}
\newlabel{Censoring}{{2}{5}}
\citation{wong2004}
\citation{savage1969}
\citation{pettitt1983,pettitt1982}
\citation{hoff2013}
\citation{lewis2012}
\citation{doksum1990}
\citation{clarke1995}
\citation{yuan2004}
\citation{hwang2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Generalization}{6}}
\newlabel{FullLikelihood}{{3}{6}}
\newlabel{RestrictedPosterior}{{4}{6}}
\newlabel{RestrictedpredDist}{{5}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Literature review}{6}}
\citation{pratt1965}
\citation{tavare1997,pritchard1999,marjoram2003,fearnhead2012}
\citation{joyce2008}
\citation{stigler1977}
\citation{lee2014}
\citation{huber2009}
\@writefile{toc}{\contentsline {section}{\numberline {3}Illustrative Examples}{8}}
\newlabel{illustrations}{{3}{8}}
\citation{rousseeuw1987}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Results from the analysis of the speed of light data. Top: Posterior distributions of $\beta $ under each model. Bottom: Log posterior predictive distributions under each model. The differences in the tails are emphasized in the bottom plot. The horizontal axis is strategically labeled to help compare the centers of the distributions in each of the plots.\relax }}{10}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:newcomb_post}{{1}{10}}
\citation{kass1995reference}
\citation{huber1964}
\citation{lewis2014}
\@writefile{toc}{\contentsline {section}{\numberline {4}Restricted Likelihood for the Linear Model}{12}}
\newlabel{BayesLinMod}{{4}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Pointwise posterior predictive intervals of log(calls) under the normal theory model fit to the non-outliers, the restricted likelihood model with Tukey's M-estimator for the slope and intercept with Huber's `proposal 2' for scale, and a heavy-tailed t-distribution model. The first three data points were used to specify the prior with each model using the remaining 21 for fitting. The normal theory model was also fit after removing observations 14-20 (years 1963 - 1970).\relax }}{13}}
\newlabel{fig:calls_predictive}{{2}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}The Bayesian linear model}{14}}
\newlabel{LinearModel}{{8}{14}}
\newlabel{fullRank}{{C1}{14}}
\newlabel{supReal}{{C2}{14}}
\newlabel{asb}{{C3}{14}}
\newlabel{as}{{C4}{14}}
\newlabel{regEq}{{C5}{14}}
\newlabel{scaleEqReg}{{C6}{14}}
\citation{huber2009,maronna2006}
\citation{lewis2014}
\citation{gelfand1990}
\citation{liu1994,liang2008}
\citation{hastings1970}
\newlabel{regIn}{{C7}{15}}
\newlabel{scaleEq2Reg}{{C8}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Computational strategy}{15}}
\newlabel{highDim}{{4.2}{15}}
\newlabel{MHRatio}{{9}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Construction of the proposal}{17}}
\newlabel{Transformation}{{4.1}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A depiction of $\mathcal  {A}$, $\Pi (\mathcal  {A})$, and the unit circle for the illustrative example where $b_{1}(\mathbf  {1},\unhbox \voidb@x \hbox {\relax \mathversion  {bold}$y$})=\qopname  \relax m{min}(\unhbox \voidb@x \hbox {\relax \mathversion  {bold}$y$})=0$ and $s(\mathbf  {1},\unhbox \voidb@x \hbox {\relax \mathversion  {bold}$y$})=\DOTSB \sum@ \slimits@ (y_i -b_{1}(\mathbf  {1},\unhbox \voidb@x \hbox {\relax \mathversion  {bold}$y$}))^2 =1$. $\mathcal  {A}$ is the combination of three quarter circles, one on each plane defined by $y_i=0$. The projection of this manifold onto the deviation space is depicted by the bowed triangular shape in the plane defined by $\DOTSB \sum@ \slimits@ y_i=0$. The circle in this plane represents the sample space for the intermediate sample $\unhbox \voidb@x \hbox {\relax \mathversion  {bold}$z$}^*$. Also depicted is the vector $\mathbf  {1}$, the design matrix for the location and scale setting.\relax }}{19}}
\newlabel{fig:sampSpace}{{3}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Evaluation of the proposal density}{19}}
\newlabel{gradSTheoremReg}{{4.2}{20}}
\newlabel{cosine}{{12}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visualization of the scaling from $z^{*}$ to $z$. Left: the first substep scales $z^{*}$ on the unit circle to the circle of radius $r = ||z||$, resulting in a change-of-variables transformation for the unit circle to a circle of radius $r$. The contribution to the Jacobian of this transformation is $r^{-(n-p-1)}$. Right: The second substep accounts for the the change-of-variables transformation from the circle of radius $r$ to $\Pi (\mathcal  {A})$. The normal vectors to these two sets are used to calculate the contribution to the Jacobian of this part of the transformation are shown in the figure.\relax }}{21}}
\newlabel{fig:stretchDeform}{{4}{21}}
\newlabel{lem:basis}{{4.3}{21}}
\citation{miao1992}
\newlabel{lem:fullrank}{{4.4}{22}}
\newlabel{eq:volume}{{13}{22}}
\newlabel{Jacobian}{{4.5}{22}}
\citation{miao1992}
\newlabel{dens:ystst}{{14}{23}}
\newlabel{theorem:sings}{{4.7}{23}}
\newlabel{Mest}{{15}{24}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Simulated Data}{24}}
\newlabel{simData}{{5}{24}}
\newlabel{gensim2}{{16}{24}}
\citation{huber2009}
\newlabel{fullsim2}{{17}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The nine different inverse gamma priors used for the group level variance parameters $\sigma _{j}^{2}$ in the simulation. The shape parameter values are $a_{s} = 1.25, 5, 10$. The scale parameter values are $b_{s} = 4a_{s}c$ with $c = 0.5, 1, 2$. The vertical dashed line in each panel is at the true value of $\sigma ^{2} = 4$ and is the variance of the good portion of the data in the simulation.\relax }}{26}}
\newlabel{fig:priors}{{5}{26}}
\newlabel{kl}{{18}{26}}
\citation{huber2009}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Average KL-divergence plus/minus one standard error for each value of $a_{s}$ and $c$ ($\overline  {KL}^{(M)}_{{\cdot }{\cdot }} \pm SE(\overline  {KL}^{(M)}_{{\cdot } k})$). Smaller values represent better fits. The panels correspond to $c = 0.5$ (left), $c=1$ (middle), and $c=2$ (right), with the values of $a_{s}$ on the horizontal axis. The average KL for the normal theory model ranges from $0.22$ to $0.3$ and is left out of the figure.\relax }}{28}}
\newlabel{kl_sim}{{6}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Average KL-divergence plus/minus one standard error grouped by the factors $m$ (left), $n$ (middle), and $p$ (right). These results are for the single prior with $a_s = 5$ and $c = 1$.\relax }}{29}}
\newlabel{kl_mnp}{{7}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Real Data}{29}}
\newlabel{RealData}{{6}{29}}
\citation{zellner1986,liang2008}
\citation{kass1995reference}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}State Level Regression model}{30}}
\newlabel{regModelNW}{{6.1}{30}}
\newlabel{eq:regModel}{{19}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The square root of (scaled) count in 2012 versus that in 2010 for four states. The colors represent the varying contractual agreements as they stood in 2010 (`Type'). Agencies that closed during the 2010-2012 period are represented by the zero counts for 2012.\relax }}{31}}
\newlabel{fig:ctVct}{{8}{31}}
\citation{ronchetti1997}
\citation{jung2014}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Method of model comparison}{32}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}Comparison of predictive performance}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Average TLM plus/minus one standard deviation over $K = 50$ splits into training and holdout samples. The panels are for the different states 2, 15, 27, and 36, with $n = 222, 40, 117,$ and $46$, respectively. The horizontal axis is the percent of $n$ used in each training set. The color corresponds to the fitting model. Larger values of TLM are better.\relax }}{35}}
\newlabel{fig:tlm}{{9}{35}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Hierarchical regression model}{35}}
\newlabel{hierRegNW}{{6.2}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Average TLM plus/minus one standard deviation over $K = 50$ splits into training and holdout samples for several values of the trimming fraction $\alpha $. The training sample size used is $0.5n$. Larger values of TLM are better.\relax }}{36}}
\newlabel{fig:tlmbyAlpha}{{10}{36}}
\newlabel{eq:hierModel}{{20}{36}}
\citation{gelman2006}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Hierarchical model results: $\overline  {TLM}_b(A)_{\cdot }$ plus/minus one standard deviation over $K = 50$ splits into training and holdout sets with the Student-t as the base model and several values of the trimming fraction $\alpha $. Larger values of TLM are better.\relax }}{39}}
\newlabel{fig:hierTLM}{{11}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Hierarchical model results: ${TLM}_b(A)_{j}$ plus/minus one standard deviation over $K = 50$ repetitions for each state and $\alpha = 0.3$. The states are ordered along the $x$-axis according to number of agencies within the state (shown in parentheses). Results displayed are for the robust models using Tukey's M-estimators. Larger values of TLM are better.\relax }}{40}}
\newlabel{fig:hierTLMstate}{{12}{40}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{40}}
\newlabel{Conclusions}{{7}{40}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Appendix}{42}}
\newlabel{sec:appendix}{{8}{42}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Proofs}{42}}
\newlabel{1to1onto}{{8.1}{43}}
\newlabel{perpGradReg}{{8.1}{43}}
\newlabel{eq:lem3.2}{{26}{43}}
\newlabel{BigMatrix}{{27}{44}}
\citation{miao1992}
\newlabel{MBI:lemma}{{8.2}{45}}
\newlabel{MBI:thm}{{8.3}{45}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Setting the hierarchical prior values}{46}}
\bibstyle{apa}
\bibdata{refPaper1}
\bibcite{berger2006}{{1}{2006}{{Berger}}{{}}}
\bibcite{bernardo2000}{{2}{2000}{{Bernardo and Smith}}{{}}}
\bibcite{clarke1995}{{3}{1995}{{Clarke and Ghosh}}{{}}}
\bibcite{clarke2013Complete}{{4}{2013}{{Clarke et~al.}}{{}}}
\bibcite{clyde2004}{{5}{2004}{{Clyde and George}}{{}}}
\bibcite{clyde2013}{{6}{2013}{{Clyde and Iversen}}{{}}}
\bibcite{doksum1990}{{7}{1990}{{Doksum and Lo}}{{}}}
\bibcite{fearnhead2012}{{8}{2012}{{Fearnhead and Prangle}}{{}}}
\bibcite{garthwaite2005}{{9}{2005}{{Garthwaite et~al.}}{{}}}
\bibcite{gelfand1990}{{10}{1990}{{Gelfand and Smith}}{{}}}
\bibcite{gelman2006}{{11}{2006}{{Gelman}}{{}}}
\bibcite{hastings1970}{{12}{1970}{{Hastings}}{{}}}
\bibcite{hoff2013}{{13}{2013}{{Hoff et~al.}}{{}}}
\bibcite{huber2009}{{14}{2009}{{Huber and Ronchetti}}{{}}}
\bibcite{huber1964}{{15}{1964}{{Huber}}{{}}}
\bibcite{hwang2005}{{16}{2005}{{Hwang et~al.}}{{}}}
\bibcite{joyce2008}{{17}{2008}{{Joyce and Marjoram}}{{}}}
\bibcite{jung2014}{{18}{2014}{{Jung et~al.}}{{}}}
\bibcite{kass1995}{{19}{1995}{{Kass and Raftery}}{{}}}
\bibcite{kass1995reference}{{20}{1995}{{Kass and Wasserman}}{{}}}
\bibcite{lee2014}{{21}{2014}{{Lee and MacEachern}}{{}}}
\bibcite{lewis2014}{{22}{2014}{{Lewis}}{{}}}
\bibcite{lewis2012}{{23}{2012}{{Lewis et~al.}}{{}}}
\bibcite{liang2008}{{24}{2008}{{Liang et~al.}}{{}}}
\bibcite{liu1994}{{25}{1994}{{Liu}}{{}}}
\bibcite{marjoram2003}{{26}{2003}{{Marjoram et~al.}}{{}}}
\bibcite{maronna2006}{{27}{2006}{{Maronna et~al.}}{{}}}
\bibcite{miao1992}{{28}{1992}{{Miao and Ben-Israel}}{{}}}
\bibcite{ohagan2006}{{29}{2006}{{O'Hagan et~al.}}{{}}}
\bibcite{pettitt1982}{{30}{1982}{{Pettitt}}{{}}}
\bibcite{pettitt1983}{{31}{1983}{{Pettitt}}{{}}}
\bibcite{pratt1965}{{32}{1965}{{Pratt}}{{}}}
\bibcite{pritchard1999}{{33}{1999}{{Pritchard et~al.}}{{}}}
\bibcite{ratcliff1993}{{34}{1993}{{Ratcliff}}{{}}}
\bibcite{ronchetti1997}{{35}{1997}{{Ronchetti et~al.}}{{}}}
\bibcite{rousseeuw1987}{{36}{1987}{{Rousseeuw and Leroy}}{{}}}
\bibcite{savage1969}{{37}{1969}{{Savage}}{{}}}
\bibcite{stigler1977}{{38}{1977}{{Stigler}}{{}}}
\bibcite{tavare1997}{{39}{1997}{{Tavar{\'e} et~al.}}{{}}}
\bibcite{wong2004}{{40}{2004}{{Wong and Clarke}}{{}}}
\bibcite{yuan2004}{{41}{2004}{{Yuan and Clarke}}{{}}}
\bibcite{yuan1999minimally}{{42}{1999}{{Yuan and Clarke}}{{}}}
\bibcite{zellner1986}{{43}{1986}{{Zellner}}{{}}}
\bibcite{zhu2011}{{44}{2011}{{Zhu et~al.}}{{}}}
